---
title: "Estimate Robustness of Real Networks"
output: html_notebook
---


```{r setup}
library(tidyverse)

# for parallel processing
library(foreach)
library(doParallel)
```


Loop over web-of-life networks and calculate robustness.


```{r load-one-dataset}

all_files <- dir("data/")

remove_these <- c(grep("README", all_files), grep("references", all_files))

all_webs <- all_files[-remove_these]
```


Pick the first one to test

```{r one-web}

web <- read.csv(paste0("data/", all_webs[1]))

# rows are traits
N <- nrow(web)

# columns are species
S <- ncol(web)

c <- (N / sum(web)) * log(S)

```

Explore the sizes of the networks

```{r explore-properties}
res_S <- res_N <- test_traits <- 
  var_traits <- mean_traits <- est_p <- dispersion_test <- 
  numeric(length(all_webs))

for (i in 1:length(all_webs)) {
  
  # read in the web and convert to binary
  tmp <- sign(read.csv(paste0("data/", all_webs[i])))
  
  res_S[i] <- ncol(tmp)
  res_N[i] <- nrow(tmp)
  
  
  test_traits[i] <- min(rowSums(tmp))
  var_traits[i] <- var(rowSums(tmp))
  mean_traits[i] <- mean(rowSums(tmp))
  est_p[i] <- sum(tmp) / (res_S[i] * res_N[i])
  dispersion_test[i] <- (var_traits[i] / mean_traits[i]) * (1/(1-est_p[i]))
  
  # res_c[i] <- complexityEstimate(tmp)
  # res_r[i] <- sampleRobustness(tmp, nb = 100)
  
  # print(i)
}

plot(res_S ~ res_N)
print(test_traits)
print(var_traits)
```

## Define some functions

```{r complexity-function}

complexityEstimate <- function(A) {
  
  # rows are traits
  N <- nrow(A)
  
  # columns are species
  S <- ncol(A)
  
  c <- (N / sum(A)) * log(S)
  
  
}

```

```{r resample-robustness}

sampleRobustness <- function(A, nb = 1000){
  
  # number of Species
  S <- ncol(A)
  
  # vector of results
  res <- numeric(nb)
  
  # loop over replicates
  for (k in 1:nb) {
    
    species <- sample(S)
    
    # premute within rows
    Aperm <- A[,species]
    
    rob <- robustness(Aperm)
    
    res[k] <- rob
    
  }
  
  
return(mean(res))  
  
}

```

```{r robsutness-function}

robustness <- function(Aperm){
  
   # number of Species
  S <- ncol(Aperm)
  
  # number of traits
  N <- nrow(Aperm)
  
  nn <- 0
  mm <- 0
  
  while (mm==0 & nn <= S) {
    nn <- nn + 1
    # mm <- min(rowSums( matrix(Aperm[, 1:nn], nrow = N, ncol = nn) ))
    mm <- min(rowSums( as.matrix(Aperm[, 1:nn])))
  }
  
  return( (S-nn+1) / (S * 1.0))
}

```


<hr>
<hr>
Here's my function to compute robustness. A is the NxS trait-species matrix; nb is the number of random extinction sequences (keeping in mind that there are only  S(S-1) different.  sequences). Mind for mistakes on my part!

def robustness(A,nb):
    S=len(A[0,:])              #number of species
    r=[ ]                            #will become the array of number of species loss before trait loss for all the random extinction sequences
    for k in range(nb):
        species=np.random.permutation(S) #a random permutation of species order
        Aperm=A[:,species]                           
        n=0
        m=0        
        while (m==0)&(n<=S):
            n=n+1
            m=min(np.sum(Aperm[:,:n],axis=1)) 

#for  each trait compute the number of species, amongst the last n ones,  that have that trait, take the min over all traits. If this min is 0, that means that the trait  already gone. Thus we increment to check if that is true for n+1  remaining species. When this is no longer the case, we can affirm that exactly  S + 1  - n extinctions led to the loss of one trait.  repeat nb times. 

        r=np.concatenate([r,  [S-n+1] ])
    return np.mean(r)/S
    
<hr>    
<hr>

Loop over all webs

```{r loop-webs}

# vector to store complexity results
res_c <- numeric(length(all_webs))
res_r <- res_c

for (i in 1:length(all_webs)) {
  
  tmp <- sign(read.csv(paste0("data/", all_webs[i])))
  
  res_c[i] <- complexityEstimate(tmp)
  res_r[i] <- sampleRobustness(tmp, nb = 200)
  
  print(i)
}

plot(res_r ~ res_c, type = "p", subset = dispersion_test <= Inf)
new_c <- seq(0,2.5, length = 100)
lines(new_c, c0.7*exp(-3.5*new_c**2)+.3*exp(-0.8*new_c))

save(list = ls(), file = "first_run.rda", compress = "xz")

```

Convert to data.frame for processing

```{r}

df <- data.frame(complexity = res_c,
                 robustness = res_r,
                 n_species = res_S,
                 n_traits = res_N, 
                 var_traits = var_traits,
                 mean_traits = mean_traits,
                 est_p = est_p,
                 dispersion_test = dispersion_test,
                 residual = res_r - ( 0.7*exp(-3.5*res_c**2)+.3*exp(-0.8*res_c))
                 )

new_c <- seq(0, 2.5, length = 100)
est_r <- 0.7*exp(-3.5*new_c**2)+.3*exp(-0.8*new_c)

fit_df <- data.frame(new_c = new_c, 
                     est_r = est_r)


```

## Plot results

```{r}

g1 <- ggplot(df, aes(x = complexity,
                     y = robustness,
                     color = log10(dispersion_test))) + 
  geom_point() + 
  scale_color_viridis_c() + 
  geom_line(data = fit_df, mapping = aes(x = new_c, y = est_r, color = NULL))

print(g1)

ggsave(g1,filename = "robust-complexity.jpeg", width = 10, height = 7)

```

```{r residuals-to-estimated-line}

g2 <- ggplot(df, aes(x = complexity,
                     y = residual,
                     color = log10(dispersion_test))) + 
  geom_point() + 
  scale_color_viridis_c() + 
  geom_hline(yintercept = 0)
print(g2)

ggsave(g2,filename = "resid-complexity.jpeg", width = 10, height = 7)

```

```{r}

g3 <- ggplot(df, aes(x = log10(dispersion_test),
                     y = residual,
                     color = log10(dispersion_test))) + 
  geom_point() + 
  scale_color_viridis_c() + 
  geom_hline(yintercept = 0)
print(g3)

ggsave(g3,filename = "resid-dispersion.jpeg", width = 10, height = 7)

```






## Test on Jeff's original seed dispersal network

```{r jeff-test}

testA <- read.table("data/interactions.txt", header = TRUE)

#coerce to matrix and binary
testA <- sign(as.matrix(testA))

r <- sampleRobustness(testA, nb = 100)
c <- complexityEstimate(testA)

```










