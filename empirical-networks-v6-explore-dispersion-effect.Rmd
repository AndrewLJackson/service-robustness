---
title: "Estimate Robustness of Real Networks"
output: html_notebook
author: Andrew L Jackson, Jean-Francois Arnoldi, Sam P. Ross & Ian Donohue
date: "`r format(Sys.time(), '%d %B %Y')`"
---


```{r setup}
library(lme4)
library(tidyverse)
library(furrr) # for parallel implmenetation of purrr
library(latex2exp) # for latex style equations in figures
library(patchwork)
library(rjags)

```

## Import the Web of Life data

Loop over the datasets and import them into a list.

```{r import-webs}

# get all file names in the folder data/
all_files <- dir("data/")

# find the indices that are README or reference files
remove_these <- c(grep("README", all_files), grep("references", all_files))

# remove them from the vector of names and prepend the data/ folder address
all_web_files <- paste0("data/", all_files[-remove_these])

# import all the webs and covert then to binary association form
all_webs <- map(all_web_files, ~sign(read.csv(.x)))

# add names to each of the list entries. Required by map()
names(all_webs) <- all_web_files

# a table of all the webs by type
types <- unlist(map(names(all_webs), ~substr(.x, 8, 9)))
n_types <- table(types)

```


We used all the available bipartite webs from [http://www.web-of-life.es](Web of Life) as downloaded on 18 Febrary 2020. The original matrices included measures of times recorded, which we converted to binary association matrices. Each interaction matrix types described below comprise frist the species in rows (S) and second the traits (N) by columns for example for species of Anemone (rows) provide habitat for Fish (columns):

+ AF = Anemone - Fish (n = `r n_types["AF"]`)
+ HP = Host - Parasite (n = `r n_types["HP"]`)
+ PA = Plant - Ant (n = `r n_types["PA"]`)
+ PH = Plant - Herbivore (n = `r n_types["PH"]`)
+ PL = Plant - Pollinator (n = `r n_types["PL"]`)
+ SD = Seed - dispersers (n = `r n_types["SD"]`)


## Summary statistics

### Define some functions that we will use to generate summary statics

A function to calculate our measure of complexity for a given web. 

```{r complexity-function}

complexityEstimate <- function(A) {
  
  # rows are traits
  N <- nrow(A)
  
  # columns are species
  S <- ncol(A)
  
  # original complexity estimate
  c <- (N / sum(A)) * log(S)
  
  # new complexity estimate 3/Feb/2020
  # c <- N * log(N) / sum(A)
  
  # 6/feb/2020 
  log_q <- -log ( (S * N - sum(A)) / (S * N))
  c <- (1/S) * (log(N) / log_q)
  
  return(c)
  
}


```

A function to calculate our measure of fragility $f$, 

$$f= \frac{1}{S} \frac{\log(N)}{|\log(q)|}$$ 

where q=1-p and p is the connectance estimated as p~#links/(SxN). I wrote this more cleanly in overleaf. 

```{r fragility}
fragilityEstimate <- function(A) {
  
  # rows are traits
  N <- nrow(A)
  
  # columns are species
  S <- ncol(A)
  
  # connectance measures
  p <- sum(A) / (S * N)
  q <-  1 - p
  
  # fragility
  # lines below are equivalent
  # f <- (1/S) * (log(N) / abs(log(q)))
  f <- -log(N) / log(q) / S
  
  
  return(f)
  
}
```



A function to calculate the robustness of a given web.

```{r robustness-function}

robustness <- function(Aperm, S = ncol(Aperm)){
  
  nn <- 0
  mm <- 0
  
  # move along columns from left to right until we lose a trait
  while (mm==0 & nn <= S) {
    nn <- nn + 1
    mm <- min(rowSums( as.matrix(Aperm[, 1:nn])))
  }
  
  return( (S-nn+1) / (S * 1.0))
}

```

A function to take a given web, repeatedly resample it and remove species until it breaks. This lets us create an estimate of the mean robustness of a given web given random extinctions.

```{r resample-robustness}

shuffleExinctionSingle <- function(A, S) {
  
  # generate a permuation for species in A
  species <- sample(S)
  
  # premute within rows
  Aperm <- A[,species]
  
  # calculate robustness
  rob <- robustness(Aperm)
  
  return(rob)
  
}

sampleRobustness <- function(A, S = ncol(A), nb = 10){
  
  # loop over replicates using parallel furrr map function.
  res <- future_map_dbl(1:nb, ~shuffleExinctionSingle( A, S))
  
  # return the mean of the results vector which is mean of 
  return(mean(res))  
  
}

```

A gaussian-exponential function to estimate robustness from fragility

```{r predict-robustness-from-fragility}

predictRobustness <- function(x) {exp(-x - (2/3)* x ^2 )}

```


### Apply our functions to each web

Calculate some summary statistics on each web and conver to data.frame format.

```{r summary-statistics}



df_webs <-  all_webs %>% 
  map_dfr(~data.frame(S = as.numeric(ncol(.x)),
                      N = as.numeric(nrow(.x)),
                      sum_A = as.numeric(sum(.x)),
                      min_S_per_N = min(rowSums(.x)),
                      var_S_per_N = var(rowSums(.x)),
                      mean_S_per_N = mean(rowSums(.x)),
                      est_p = sum(.x) / (ncol(.x) * nrow(.x)),
                      complexity = complexityEstimate(.x),
                      fragility = fragilityEstimate(.x),
                      .id = "file"
  )) %>% 
  mutate(web_type = types)

# calculate dispersion, where the expected value according to the binomial 
# distributio is 1.
df_webs <- df_webs %>%
  mutate(dispersion = (var_S_per_N / mean_S_per_N) * 
                        (1 / 1 - est_p))


```

If we assume that species S are connected to traits N according to a binomial distribution then we calculate how the empirical networks deviate from this prediction. Speficically, the first two moments of the binomial distribution (with random variable $x$) are given by $\bar{x} = pq$ and $\text{Var}(x) = npq$ where $q = 1-p$.  We can then define Dispersion $d$ as the proportional deviance from 1 of the sample estimated 

$$d  = \frac{1}{q} \frac{\text{Var}(S_n)}{\bar{S_n}}$$




## Simulate Extinctions to calculate robustness

```{r simulate-extinctions}

n_samples <- 500

do_robustness <- FALSE

if (do_robustness == TRUE ) {
  
  # set up the multicore for the function sampleRobustness which calls them.
  # im not sure if i should do this within sampleRobustness or if its ok to 
  # do it once here outside.
  plan(multisession(workers = 3))
  
  robustness_results <- all_webs %>% 
    map_dbl(~sampleRobustness(.x, nb = n_samples))
  
  save(robustness_results, file = "robustness_run.rda", compress = "xz")

  
}

if (do_robustness == FALSE){
  print("NB sampling for robustness not run. Loaded instead from previous run.")
  load("robustness_run.rda")
}

# Add the robustness estimate to the data.frame and 
# calcuate the residual to Jeff's model
df_webs <- df_webs %>% 
  mutate(robustness = robustness_results)

df_webs <- df_webs %>% 
  mutate(residual = robustness - predictRobustness(complexity))

# add the estimated fragility for each network based on their fragility
df_webs <- df_webs %>% mutate(robustness_hat = predictRobustness(fragility))

```

Random sampling of  extinctions until loss of any trait was simulate with $n =$ `r n_samples` on each of the empirical interaction networks and the mean proportion of extinctions taken as the robustness $R$ for that network.



## Filter webs

We remove webs that have only 1 trait (n = 3) and webs that show no variation in the number of species S per trait N (n = 4, and all of which are Anemone-Fish type webs, all of which had anemones being associated with only 1 or 0 species of fish).

```{r filter-webs}

df_webs <- df_webs %>% filter( dispersion != 0.0 & !is.na(var_S_per_N) )

```



## Plot results

Here we set some plotting parameters for consistency across panels.

```{r plot-defaults}

axis_text_size <- 10
axis_title_size <- 14

```


In order to plot the analytical model, we create a dataframe object of a sequence of fragility values spanning out observed range and the corresponding predicted robustness ($\hat{R}$). 

```{r create-a-dataframe-for-jeffs-model}

new_f <- seq(from = 0, to = 2.5, length.out = 100)

# the estimated Robusteness (Rhat)
est_r <- exp(-new_f - new_f^2) #predictRobustness(new_f)

fit_df <- data.frame(new_f = new_f, 
                     est_r = est_r)


```



```{r}

g1 <- ggplot(df_webs, aes(x = fragility,
                     y = robustness,
                     color = log10(dispersion))) + 
  geom_point() + 
  # scale_color_viridis_c(guide = 
  #                         guide_legend(override.aes = list(color = "white"))) +
  # scale_color_viridis_c(limits = c(-1.5, 1.5)) + 
    scale_color_viridis_c() + 
  geom_path(data = data.frame(xx = c(0, 1), 
                              yy = c(1, 0)),
            mapping = aes(x = xx, y = yy),
            color = "black") + 
  geom_line(data = fit_df, mapping = aes(x = new_f, y = est_r, color = NULL), 
            linetype = 2) + 
  ylab("Robustness (R)") + 
  xlab("Fragility (f)") +
   labs(color = expression(log[10](d))) +
  theme_classic() + 
  theme(axis.text = element_text(size = axis_text_size),
        axis.title = element_text(size = axis_title_size)) #+ 
  # theme(
  #       legend.text = element_text(color = "white"),
  #       legend.title = element_text(color = "white")
  #       ) 


print(g1)
# 
ggsave(g1,filename = "images/robust-fragility-empirical.png",
       width = 20, height = 12, units = "cm",
       scale = 1)

```



```{r jags-random-slopes}

modelstring <- '
model {
  
  for(i in 1:N) { 
    
    # likelihood of data
    y[i] ~ dnorm(mu[i], tau)
    
    # specify the mean
    mu[i] <- a + b[G[i]] * X[i]
  }
  
  # Calculate the random part of the slope
  for(j in 1:J) {
    
    b[j] ~ dnorm(0, tau_b)
    
  }
  
  # Priors on the fixed part
  #a ~ dnorm(0, 10^-6)
  a <- 0
  
  # priors on the variances
  tau ~ dunif(0, 100)
  tau_b ~ dunif(0, 100)
  
  # mean of the slopes
  b_mean <- mean(b)
}
'

```



```{r}

df_webs <- df_webs %>% mutate(residRf = robustness -1 + fragility,
                              log10d = log10(dispersion))

# model of the residuals of R = 1-f tor f<1 on log(dispersion)
mRf <- lm( residRf ~ -1 + log10d, 
           data = df_webs %>% filter(fragility < 1))

# when fitting without an intercept we need to manually add in a = 0
cc <- c(0, coef(mRf))

# Create a copy of web_type that is a factor as lmer() wants it.
df_webs <- df_webs %>% mutate(web_type_fac = as.factor(web_type))

# fit the random slopes model
mRf_me <- lmer( residRf ~   log10d + 
                  ( log10d | web_type_fac ), 
              data = df_webs %>% filter(fragility < 1))

# Build a dataframe to plot the fitted lines for the different web types
# Only need two points to fit a line

random_slopes <- broom::augment(mRf_me)

test_slope <- broom::augment(mRf)

# =============================================================================
# FIT A JAGS MODEL WITH RANDOM SLOPES ONLY
data = with(df_webs, { 
  list(y = residRf,
       X = log10(dispersion),
       G = as.integer(df_webs$web_type_fac),
       N = nrow(df_webs),
       J = length(levels(web_type_fac))
  )
})

model_1 = jags.model(textConnection(modelstring), data=data,n.chain=3)

mRf_jags <- coda.samples(model = model_1,
                         variable.names=c('a','b', 'tau', 'tau_b', 'b_mean'),
                         n.iter=10000,thin=10)

# extract the mean of posterior coefficients
mRf_jags_summary <- summary(mRf_jags)

# pick two points on x to evaluate the fitted model over and expand them
new_xx <- c(rep(-1,6), rep(1,6))
new_yy <- new_xx * c(mRf_jags_summary$statistics[2:7,1],
                     mRf_jags_summary$statistics[2:7,1])

new_dat <- data.frame(new_xx = new_xx,
                      new_yy = new_yy,
                      web_type_fac = c(levels(df_webs$web_type_fac),
                                       levels(df_webs$web_type_fac)))






```

```{r random-slopes-plotting}

g3_simplified <- ggplot(df_webs %>% filter(fragility < 1), 
                        aes(x = log10(dispersion),
                            y = residRf,
                            color = web_type_fac,
                            shape = web_type_fac)) + 
  geom_point() + 
  scale_color_viridis_d() + 
  geom_hline(yintercept = 0, color = "grey", linetype = 2) + 
  geom_vline(xintercept = 0, color = "grey", linetype = 2) + 
  # geom_smooth(method = lm) +
  geom_abline(slope = mRf_jags_summary$statistics["b_mean", "Mean"],
              intercept = 0,
              color = "black",
              size = 1.5,
              linetype = 2) +
  geom_line(data = new_dat,
            mapping = aes(x = new_xx,
                          y = new_yy)) + 
  # geom_line(data = random_slopes, 
  #           mapping = aes(x = I.log10.dispersion..,
  #                         y = .fitted,
  #                         color = web_type_fac)) + 
  # geom_line(data = broom::augment(mRf),
  #           mapping = aes(x = log10.dispersion.,
  #                         y = .fitted,
  #                         color = NULL,
  #                         shape = NULL),
  #           color = "black") + 
  labs(color = "Web Type", 
       shape = "Web Type") + 
  ylab(TeX("$(R -1 + f)$ , $f<1$")) + 
  xlab(TeX("$\\log_{10}(\\dispersion)$")) +
  theme_classic() + 
  theme(axis.text = element_text(size = axis_text_size),
        axis.title = element_text(size = axis_title_size))
  

print(g3_simplified)

ggsave(g3_simplified,
       filename = "images/resid-dispersion-random-slopes-only.png", 
       width = 20, height = 12, units = "cm")

```

```{r random-slopes-plotting-test}

g3_test <- ggplot(df_webs %>% filter(fragility < 1), 
                        aes(x = log10(dispersion),
                            y = residRf,
                            color = web_type_fac,
                            shape = web_type_fac)) + 
  geom_point() + 
  scale_color_viridis_d() + 
  geom_hline(yintercept = 0, color = "grey", linetype = 2) + 
  geom_vline(xintercept = 0, color = "grey", linetype = 2) + 
  # geom_smooth(method = lm) +
  # geom_line(data = new_dat,
  #           mapping = aes(x = new_xx,
  #                         y = new_yy)) + 
  geom_line(data = random_slopes,
            mapping = aes(x = log10d,
                          y = .fitted,
                          color = web_type_fac)) +
  # geom_line(data = test_slope,
  #           mapping = aes(x = log10d,
  #                         y = .fitted,
  #                         color = NULL,
  #                         shape = NULL)) +
  # geom_line(data = broom::augment(mRf),
  #           mapping = aes(x = log10.dispersion.,
  #                         y = .fitted,
  #                         color = NULL,
  #                         shape = NULL),
  #           color = "black") + 
  labs(color = "Web Type", 
       shape = "Web Type") + 
  ylab(TeX("$(R -1 + f)$ , $f<1$")) + 
  xlab(TeX("$\\log_{10}(\\dispersion)$")) +
  theme_classic() + 
  theme(axis.text = element_text(size = axis_text_size),
        axis.title = element_text(size = axis_title_size))
  

print(g3_test)

ggsave(g3_test,
       filename = "images/resid-dispersion-random-slopes-random-intercepts.png",
       width = 20, height = 12, units = "cm")

```


Plot these two figures together using `patchwork`

```{r stitch-figs-a-b, fig.width=12, fig.height=6}

# g_ab <- (g1 | g3_simplified)
# 
# print(g_ab)
# 
# ggsave(filename = "frag-robust-disp.png", plot = g_ab, 
       # width = 15, height = 9, units = "cm")

```


**Figure S2.1**. **(a)** The relationship between simulated robustness and analytically esimated fragility as calculated on the $n = $ `r nrow(df_webs %>% summarise(n()))` empirical networks matches close the analytical approximation (black line). Each network is coloured by the degree of disperion ($d$) (log10 scale) according to a binomial distribution, where values below 0 represent under-dispersion, 0 is ideally dispersed and values greater than 0 indciate over-dispersion. **(b)** The residuals of the observed robustness to the analytical approximation in Figure S2.1 show a strong relationship with dispersion $\log_{10}(d)$. Colours show the same $\log_{10}(d)$ for direct comparison with points in Figure S2.1. The linear fit shown is the basis for the modified estimate of $R$ given below.

We can then use a linear model as fit to Figure S2.1b to account for dispersion for a new metric that describes Robustness ($R$) given Fragility ($f$) and Dispersion ($d$) of a given network.



## Calculate modified measure of fragility $f^*$

```{r}

# regress robsustness against (1 - fragility) and then esimate the coefficient
# of the linear regression of the residuals to this plot against
# log10(dispersion) and calculate
# fstar = fragility + lambda * log10(dispersion)
df_webs <- df_webs %>% 
  mutate(fstar = pmax(fragility - cc[1] - cc[2] * 
           log10(dispersion), runif(n(), 0, 0.1)))

```

write the dataframe to file for sharing

```{r}
# and write to file
write_csv(df_webs, path = "web_statistics.csv")

```





```{r corrected-figure}

g6 <- ggplot(df_webs, aes(x = fstar, 
                          y = robustness,
                          color = web_type)) + 
  geom_point() + 
  scale_color_viridis_d() + 
  geom_line(data = fit_df, mapping = aes(x = new_f, y = exp(-5/3*new_f), color = NULL)) + 
  ylab("Robustness (R)") + 
  xlab(TeX("Corrected Fragility $(f^*)$")) +
   labs(color = "Web Type", line.style = NULL) +
  theme_classic() + 
  theme(axis.text = element_text(size = axis_text_size),
        axis.title = element_text(size = axis_title_size))

print(g6)

ggsave(g6, filename = "images/R-by-fstar.png",
       width = 20, height = 12, units = "cm")


```

**Figure S2.2.** The relationship betwenn Robustness ($R$) and corrected Fragility measure $f^* = f + \lambda\log_{10}(d)$. The 

The correlation coefficients for Robustness (R) with the various estimates are:

+ $\text{cor}(R,f)$ = `r round(with(df_webs, cor(robustness, fragility, method = "spearman")), 2)`
+ $\text{cor}(R,log(d))$ = `r round(with(df_webs, cor(robustness, log(dispersion), method = "spearman")), 2)`
+ $\text{cor}(R,f^*)$ = `r round(with(df_webs, cor(robustness, fstar, method = "spearman")), 2)`



## Messing around




```{r}

resid_by_web <- broom::augment(mRf, newdata = df_webs)

g4 <- ggplot(resid_by_web, 
             aes(x = web_type_fac,
                 y = residRf - .fitted)) + 
  geom_boxplot(outlier.shape = NA) + 
  geom_jitter(mapping = aes(color = web_type_fac,
                            shape = web_type_fac), 
              width = 0.2,
              alpha = 0.7) + 
  scale_color_viridis_d() + 
  geom_hline(yintercept = 0) +
  theme_classic() + 
  theme(axis.text = element_text(size = axis_text_size),
        axis.title = element_text(size = axis_title_size)) + 
  guides(color = FALSE, shape = FALSE, alpha = FALSE) + 
  xlab("Web Type") + 
  ylab("Deviance")
      
print(g4)

ggsave(g4,filename = "images/resid-dispersion-by-web.pdf", width = 10, height = 7)


```


