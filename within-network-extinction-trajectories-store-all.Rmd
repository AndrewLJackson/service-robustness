---
title: "Within Network Species Contribution to Robustness"
output: html_notebook
---


```{r setup}

library(tidyverse)
library(magrittr)
library(furrr) # for parallel implmenetation of purrr
library(patchwork)
library(lme4)

```


Objectives:

- test whether change in fragility and robustness are correlated across loss of individual species of a network


```{r}

# load the network
# "data/M_PL_062.csv" is the largest and also has one of the lowest residuals off the exp(-fstar - fstar^2) line
# "data/M_SD_022.csv" is more manageable with 110 species and a very low residual
# "data/M_PL_031.csv"   fstar = 1.23, S = 49 ** this one works well!
# "data/M_PL_046.csv" has low fragility fstar~= 0.2 and S=44
# "data/A_PH_007.csv" has fstar=0.16 and S=64
# "data/M_SD_016.csv" has fstar=0.2 and S=61 ** this is the original one used
this_file <- "data/M_SD_016.csv"

net_data <- sign(read.csv(this_file)) %>% as.matrix()

```





## Summary statistics

### Define some functions that we will use to generate summary statics

A function to calculate our measure of fragility $f$, 

$$f= \frac{1}{S} \frac{\log(N)}{|\log(q)|}$$ 

where q=1-p and p is the connectance estimated as p~#links/(SxN).

```{r fragility}
fragilityEstimate <- function(A) {
  
  # ensure A is a matrix
  A <- as.matrix(A)
  
  # rows are traits
  N <- nrow(A)
  
  # columns are species
  S <- ncol(A)
  
  # connectance measures
  p <- sum(A) / (S * N)
  q <-  1 - p
  
  # fragility
  # lines below are equivalent
  # f <- (1/S) * (log(N) / abs(log(q))) # alternative parameterisation
  f <- -log(N) / log(q) / S
  
  
  return(f)
  
}
```



A function to calculate the robustness of a given web, defined by its association matrix $\textbf{A}$ (whose elements $a_{ij} = \{0,1\}$) by simulating extinctions of species until at least one trait is lost, which owing to our assumption of $E^*=\text{AND}$ also equates to loss of the higher level service.

```{r robustness-function}

robustness <- function(Aperm, S = ncol(Aperm)){
  
  # ensure its a matrix
  Aperm <- as.matrix(Aperm)
  
  # -------------------------------------------------------------------------
  # approach that adds species until trait is present
  # nn <- 0
  # mm <- min(rowSums( as.matrix(Aperm[, 1:nn])))
  # 
  # # move along columns from left to right adding a species until we gain a trait
  # # this is then the 
  # while (mm==0 && nn < S) {
  #   nn <- nn + 1
  #   mm <- min(rowSums( as.matrix(Aperm[, 1:nn])))
  # }
  # 
  # add <- (S-nn+1) / (S * 1.0)
  
  # -------------------------------------------------------------------------
  # AJ to do: record network fragility at start and just before loss of 
  # service. Calculate mean rate of change (divide by number of extinctions)
  # and correlate against robustness.
  #
  # now test the actual removal approach.
  
  # flip the order of species around. only needed if wanting to compare output 
  # directly with the species addition approch above
  # Aperm <- Aperm[,seq(S, 1, -1)] 
  
  # counter to track the number of speceies removed
  nn <- 0 
  
  # the logical test if all traits are present
  mm <- min(rowSums( as.matrix(Aperm[,])))
  
  # store the fragility values up to extinction
  f_trajectory <- NA * numeric(S)
  
  # number of links lost by each extinction
  links_lost <- NA * numeric(S)
  
  # move along columns from left to right until we lose a trait
  while (mm != 0 && nn < S) {
    
    
    
    # update species removal counter
    nn <- nn + 1 
    
    # Calculate fragility just prior to removing a species
    # if doing first removal, calculate fragility on the entire network
    # Aperm[,0] drops everything not nothing!
    ifelse(nn==1,
           f_trajectory[nn] <- fragilityEstimate(Aperm[,]),
           f_trajectory[nn] <- fragilityEstimate(Aperm[, -(1:(nn-1))])
           )
    
    
    # store links lost
    links_lost[nn] <- sum(Aperm[,nn])
    
    # test whether all traits are present
    mm <- min(rowSums( as.matrix(Aperm[, -(1:nn)])))
  }
  
  
  # calculate robustness
  R <- nn / S * 1.0
  
  # return both outputs
  out <- c(R = R, 
           nn = nn,
           f_trajectory = f_trajectory,
           links_lost = links_lost)
  
  # return( (S-nn+1) / (S * 1.0))
  
  return(out)
}

```

The function `shuffleExtinctionSingle()` takes a given empirical web, permute its columns, and calculate its robustness using the function `robustness` defined above. The function `sampleRobustness()` loops the call to `shuffleExtinctionSingle()` using parallel computing via the function `furr::future_map_dbl()` and returns the mean robustness across the defined number of replicates (we use `nb = 500` as defined later).

```{r resample-robustness}

shuffleExinctionSingle <- function(A, S) {
  
  # generate a permuation for species in A
  species <- sample(S)
  
  # premute within rows
  Aperm <- A[,species]
  
  # calculate robustness
  rob <- robustness(Aperm)
  
  return(rob)
  
}

sampleRobustness <- function(A, S = ncol(A), nb = 10){
  
  # loop over replicates using parallel furrr map function.
  res <- future_map_dfr(1:nb, ~shuffleExinctionSingle( A, S), .id = "replicate")
  
  # return the mean of the results vector which is mean of 
  
  return(res)  
  
}

# population variance
popVar <- function(x){
  
  x <- as.matrix(x)
  
  # number of rows, which is sample size
  n <- nrow(x)
  
  # compute and return population variance and correct it so it uses
  # n in place of n-1 as the demoninator.
  cov(x) *  (n - 1) / n
  
}

# dispersion
dispersion <- function(A){
  
  # population variance of species per trait
  var_S_per_N <-  popVar(rowSums(A))
  
  # mean of species per trait
  mean_S_per_N <- mean(rowSums(A))
  
  # p
  est_p <- sum(A) / (ncol(A) * nrow(A))
  
  # return dispersion
  return((var_S_per_N / mean_S_per_N) * (1 / 1 - est_p))
  
  
} 
```

A gaussian-exponential function to estimate robustness from fragility $R = \exp(-f - \frac{2}{3}x^2)$

```{r predict-robustness-from-fragility}

predictRobustness <- function(x) {exp(-x - (2/3)* x ^2 )}

```


## Loop over the network removing one species at a time


Calculate the stats on the full network.

```{r}

reps <- 10

f_0 <- fragilityEstimate(net_data)

d_0 <- dispersion(net_data)

# apply the dispersion correction and ensure its positive by bouncing 
# as runif(n = 1, min = 0, max = 1)
# f_star_0 <- max(f_0 - (-0.2870702 * log10(d_0)), runif(1, 0, 0.1))
f_star_0 <- f_0 - (-0.2870702 * log10(d_0))

# estimate robustness by sampling
R_0 <- sampleRobustness(net_data, nb = reps)

# R_0 %<>% mutate(pre_loss_f_star = pre_loss_f - (-0.2870702 * log10(d_0)))

```

```{r restructure-df}

# pivot to long format
res_df <- pivot_longer(R_0, 
                       cols = starts_with("f_trajectory"), 
                       names_prefix = "f_trajectory", 
                       names_to = "extinction_sequence",
                       names_transform = list(extinction_sequence = as.numeric),
                       values_to = "fragility", 
                       values_drop_na = TRUE)


res_links <-   pivot_longer(R_0,
               cols = starts_with("links_lost"),
               names_prefix = "links_lost",
               names_to = "extinction_sequence",
               names_transform = list(extinction_sequence = as.numeric),
               values_to = "links_lost",
               values_drop_na = TRUE)


# calculate f_star
res_df %<>% mutate(f_star = fragility - (-0.2870702 * log10(d_0)),
                   rank_fstar = rank(f_star))

```


```{r}
g1 <- ggplot(data = res_df, 
             mapping = aes(x = extinction_sequence, 
                           y = f_star, 
                           group = replicate)) + 
  geom_line(aes(color = nn), alpha = 0.5) + 
  scale_color_viridis_c(end = 0.9) #+
  # scale_y_log10() #+ 
  # scale_x_log10()



g1_2 <- ggplot(data = res_links, 
             mapping = aes(x = extinction_sequence, 
                           y = links_lost, 
                           group = replicate)) + 
  geom_line(alpha = 0.5) + 
  scale_color_viridis_c()


print(g1)
# print(g1_2)

```

## Fit polynomials to these curves

```{r}

offset <- as.numeric(f_star_0)

zeroed_f_star <- res_df$f_star - offset

poly_2 <- lm(zeroed_f_star ~ -1 + I((extinction_sequence-1)^2):factor(replicate),
              data = res_df)

poly_3 <- lm(zeroed_f_star ~ -1 + I((extinction_sequence-1)^3):factor(replicate),
              data = res_df)

poly_4 <- lm(zeroed_f_star ~ -1 + I((extinction_sequence-1)^3):factor(replicate),
              data = res_df)

poly_k <- lm(zeroed_f_star ~ -1 + 
               I((extinction_sequence-1)^1):factor(replicate) + 
               I((extinction_sequence-1)^2):factor(replicate) + 
               I((extinction_sequence-1)^3):factor(replicate) + 
               I((extinction_sequence-1)^4):factor(replicate),
              data = res_df)




g_poly <- g1 + 
  geom_line(data = broom::augment(poly_k, res_df), 
            mapping = aes(y = .fitted + f_star_0,
                          x = extinction_sequence), 
            alpha = 1, color = "grey") +
  theme_classic()
print(g_poly)

```





## Plot the change in f_star from start to finish

```{r}

extract_slope <- function(y, x){
  coef(lm(log(y) ~ x))[2]
}

change_in_fstar <- res_df %>% group_by(replicate) %>% 
  summarise(delta_f_star = last(f_star) - first(f_star),
            mean_diff_f_star = mean(diff(f_star)),
            log_rate_f_star = extract_slope(f_star, extinction_sequence),
            mean_rank = mean(rank_fstar),
            test = sum(f_star) / first(nn),
            R = first(R), 
            nn = first(nn))

# merge with the polynomial fit data
change_in_fstar <-  inner_join(change_in_fstar, poly_df)

```

## Plot R against area under the polynomials

```{r}
g_R_poly <- ggplot(data = change_in_fstar,
                 mapping = aes(x = area,
                               y = R)) + 
  geom_point() + 
  geom_smooth(method = "lm")

print(g_R_poly)
```


```{r}
g_R_poly_coeffs <- ggplot(data = change_in_fstar,
                 mapping = aes(x = beta,
                               y = R)) + 
  geom_point() + 
  geom_smooth(method = "lm")

print(g_R_poly_coeffs)
```




```{r}
g_rank <- ggplot(data = change_in_fstar,
                 mapping = aes(x = test,
                               y = R)) + 
  geom_point() + 
  geom_smooth(method = "lm")

print(g_rank)
```


```{r}
g2 <- ggplot(data = change_in_fstar, 
             mapping = aes(x = delta_f_star, 
                           y = R)) + 
  geom_point()

print(g2)
```


```{r}
g2_log <- ggplot(data = change_in_fstar,
                 mapping = aes(x = log_rate_f_star,
                               y = R)) + 
  geom_point() + 
  geom_smooth(method = "lm")

print(g2_log)

```


```{r}
g3 <- ggplot(data = change_in_fstar, 
             mapping = aes(x = nn, 
                           y = delta_f_star)) + 
  geom_point(alpha = 0.5) + 
  scale_x_log10() + 
  scale_y_log10() + 
  geom_smooth(method = "lm")

print(g3)

```

```{r}
g4 <- ggplot(data = change_in_fstar, 
             mapping = aes(x = mean_diff_f_star, 
                           y = R)) + 
  geom_point(alpha = 0.5)

print(g4)
```





